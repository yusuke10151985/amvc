#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸµ AIéŸ³æ¥½ãƒ“ãƒ‡ã‚ªã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ - APIçµ±åˆç‰ˆ (Phase 1)
GPT-4o APIçµ±åˆ + Runway Gen-4 APIçµ±åˆ + Whisperçµ±åˆ

æ–°æ©Ÿèƒ½:
- è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ (GPT-4o)
- è‡ªå‹•æ˜ åƒç”Ÿæˆ (Runway Gen-4)
- é«˜åº¦ãªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ (Whisper)

GitHub: https://github.com/yusuke10151985/amvc
"""

print("ğŸš€ AIéŸ³æ¥½ãƒ“ãƒ‡ã‚ªã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ - APIçµ±åˆç‰ˆ èµ·å‹•ä¸­...")
print("="*70)

# ===== STEP 1: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« =====
print("\nğŸ“¦ STEP 1: å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
import subprocess
import sys

try:
    # åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
    subprocess.check_call([sys.executable, "-m", "pip", "install", "moviepy", "pysrt", "scipy", "numpy", "-q"])
    # APIçµ±åˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
    subprocess.check_call([sys.executable, "-m", "pip", "install", "openai", "requests", "whisper", "-q"])
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
    subprocess.check_call(["apt-get", "update", "-qq"], shell=False, stderr=subprocess.DEVNULL)
    subprocess.check_call(["apt-get", "install", "-y", "ffmpeg", "-qq"], shell=False, stderr=subprocess.DEVNULL)
    print("âœ… ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ï¼")
except Exception as e:
    print(f"âš ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è­¦å‘Š: {e}")
    print("   ç¶šè¡Œã—ã¾ã™...")

# ===== STEP 2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ =====
print("\nğŸ“š STEP 2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
import os
import json
import time
import numpy as np
from scipy.io import wavfile
import moviepy.editor as mp
import pysrt
import whisper
import openai
import requests
from google.colab import files
from IPython.display import display, HTML, Video
from pathlib import Path
from typing import Tuple, List, Dict, Optional

print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")

# ===== STEP 3: APIè¨­å®š =====
print("\nğŸ”‘ STEP 3: APIè¨­å®š")

def setup_apis():
    """APIã‚­ãƒ¼ã®è¨­å®š"""
    print("ğŸ” APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
    
    # OpenAI API (GPT-4o)
    openai_key = input("OpenAI API Key (GPT-4oç”¨): ").strip()
    if openai_key:
        openai.api_key = openai_key
        print("âœ… OpenAI APIè¨­å®šå®Œäº†")
    else:
        print("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ - æ‰‹å‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«ãªã‚Šã¾ã™")
    
    # Runway API (å°†æ¥å®Ÿè£…)
    runway_key = input("Runway API Key (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): ").strip()
    if runway_key:
        os.environ["RUNWAY_API_KEY"] = runway_key
        print("âœ… Runway APIè¨­å®šå®Œäº†")
    else:
        print("âš ï¸ Runway APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ - æ‰‹å‹•æ˜ åƒç”Ÿæˆã«ãªã‚Šã¾ã™")
    
    return openai_key, runway_key

# ===== STEP 4: GPT-4oçµ±åˆé–¢æ•° =====
print("\nğŸ¤– STEP 4: GPT-4oçµ±åˆé–¢æ•°ã‚’å®šç¾©ä¸­...")

def generate_music_prompts_with_gpt4o(language: str, description: str, duration: int) -> Dict:
    """GPT-4oã§éŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ"""
    
    prompt = f"""
ã‚ãªãŸã¯éŸ³æ¥½ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€SUNO AIã§ä½¿ç”¨ã™ã‚‹æœ€é©ãªéŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è¨€èª: {language}
èª¬æ˜: {description}
é•·ã•: {duration}ç§’

ä»¥ä¸‹ã®å½¢å¼ã§JSONã‚’è¿”ã—ã¦ãã ã•ã„:
{{
  "title": "æ›²ã®ã‚¿ã‚¤ãƒˆãƒ«",
  "lyrics": "æ­Œè©ï¼ˆå„è¡Œæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰",
  "style_prompt": "SUNO AIç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
  "video_prompts": ["æ˜ åƒã‚·ãƒ¼ãƒ³1ã®èª¬æ˜", "æ˜ åƒã‚·ãƒ¼ãƒ³2ã®èª¬æ˜", "æ˜ åƒã‚·ãƒ¼ãƒ³3ã®èª¬æ˜"]
}}

è¦ä»¶:
- æ­Œè©ã¯{duration}ç§’ã®é•·ã•ã«é©ã—ãŸãƒœãƒªãƒ¥ãƒ¼ãƒ 
- ã‚¹ã‚¿ã‚¤ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯SUNO AIã§åŠ¹æœçš„
- æ˜ åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å„ã‚·ãƒ¼ãƒ³ãŒ{duration//4}ç§’ç¨‹åº¦
- å…¨ã¦{language}ã§ç”Ÿæˆ
"""
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a professional music producer and lyricist."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.8
        )
        
        content = response.choices[0].message.content
        # JSONã‚’æŠ½å‡º
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end != -1:
            json_content = content[start:end]
            return json.loads(json_content)
        else:
            raise ValueError("JSON not found in response")
            
    except Exception as e:
        print(f"âš ï¸ GPT-4oç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return generate_fallback_prompts(language, description, duration)

def generate_fallback_prompts(language: str, description: str, duration: int) -> Dict:
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æ‰‹å‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
    return {
        "title": "Cosmic Drift",
        "lyrics": """Neon rivers in the night
Chasing stars till morning light
In this city, made of glass
Future memories of the past

We're on a cosmic drift, a silent flight
Painting dreams in shades of light
A fleeting moment, in the stream
Living out a vibrant dream""",
        "style_prompt": "Epic cinematic synthwave, futuristic, ethereal female vocals, driving beat, atmospheric pads, reminiscent of Blade Runner soundtrack",
        "video_prompts": [
            "Futuristic cityscape at night with neon lights",
            "Close-up of character looking at holographic stars",
            "Abstract geometric shapes moving to music",
            "Serene figure on balcony overlooking city"
        ]
    }

# ===== STEP 5: Whisperçµ±åˆé–¢æ•° =====
print("\nğŸ™ï¸ STEP 5: Whisperçµ±åˆé–¢æ•°ã‚’å®šç¾©ä¸­...")

def advanced_align_with_whisper(wav_file: str, lyrics_file: str, output_dir: str = "./outputs") -> Tuple[Optional[str], Optional[str]]:
    """Whisperã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ"""
    print("\nğŸ¯ Whisperé«˜åº¦ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆé–‹å§‹...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("ğŸ¤– Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        model = whisper.load_model("base")
        
        # éŸ³å£°èªè­˜
        print("ğŸµ éŸ³å£°èªè­˜ä¸­...")
        result = model.transcribe(wav_file)
        
        # æ­Œè©èª­ã¿è¾¼ã¿
        with open(lyrics_file, 'r', encoding='utf-8') as f:
            lyrics_lines = [line.strip() for line in f.readlines() if line.strip()]
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆ
        segments = result["segments"]
        
        base_name = Path(wav_file).stem
        srt_output = os.path.join(output_dir, f"{base_name}_whisper_subtitles.srt")
        json_output = os.path.join(output_dir, f"{base_name}_whisper_alignment.json")
        
        subtitles = pysrt.SubRipFile()
        json_data = {"words": [], "audio_duration": result["segments"][-1]["end"] if segments else 0}
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å­—å¹•ã«å¤‰æ›
        for i, segment in enumerate(segments):
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"].strip()
            
            # å¯¾å¿œã™ã‚‹æ­Œè©ã‚’æ¢ã™
            if i < len(lyrics_lines):
                text = lyrics_lines[i]
            
            start_srt = pysrt.SubRipTime(seconds=start_time)
            end_srt = pysrt.SubRipTime(seconds=end_time)
            
            subtitle = pysrt.SubRipItem(
                index=i+1,
                start=start_srt,
                end=end_srt,
                text=text
            )
            subtitles.append(subtitle)
            
            json_data["words"].append({
                "case": "success",
                "start": start_time,
                "end": end_time,
                "word": text,
                "confidence": segment.get("confidence", 0.0)
            })
        
        # ä¿å­˜
        subtitles.save(srt_output, encoding='utf-8')
        with open(json_output, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Whisperã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº†ï¼")
        print(f"   â€¢ SRT: {srt_output}")
        print(f"   â€¢ JSON: {json_output}")
        return srt_output, json_output
        
    except Exception as e:
        print(f"âŒ Whisperã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("   ã‚·ãƒ³ãƒ—ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
        return simple_align_subtitles(wav_file, lyrics_file, output_dir)

# ===== STEP 6: ã‚·ãƒ³ãƒ—ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆé–¢æ•°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ =====
def simple_align_subtitles(wav_file: str, lyrics_file: str, output_dir: str = "./outputs"):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªæ™‚é–“ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    print("\nğŸ¯ ã‚·ãƒ³ãƒ—ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆé–‹å§‹...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        audio_clip = mp.AudioFileClip(wav_file)
        audio_duration = audio_clip.duration
        audio_clip.close()
        print(f"ğŸµ éŸ³å£°ã®é•·ã•: {audio_duration:.2f}ç§’")
    except Exception as e:
        print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None
    
    try:
        with open(lyrics_file, 'r', encoding='utf-8') as f:
            lyrics_lines = [line.strip() for line in f.readlines() if line.strip()]
        print(f"ğŸ“ æ­Œè©è¡Œæ•°: {len(lyrics_lines)}")
    except Exception as e:
        print(f"âŒ æ­Œè©ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None
    
    if len(lyrics_lines) == 0:
        print("âŒ æ­Œè©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None, None
    
    time_per_line = audio_duration / len(lyrics_lines)
    
    base_name = Path(wav_file).stem
    srt_output = os.path.join(output_dir, f"{base_name}_subtitles.srt")
    json_output = os.path.join(output_dir, f"{base_name}_alignment.json")
    
    subtitles = pysrt.SubRipFile()
    json_data = {"words": [], "audio_duration": audio_duration}
    
    for i, line in enumerate(lyrics_lines):
        start_time = i * time_per_line
        end_time = (i + 1) * time_per_line
        
        start_srt = pysrt.SubRipTime(seconds=start_time)
        end_srt = pysrt.SubRipTime(seconds=end_time)
        
        subtitle = pysrt.SubRipItem(
            index=i+1,
            start=start_srt,
            end=end_srt,
            text=line
        )
        subtitles.append(subtitle)
        
        json_data["words"].append({
            "case": "success",
            "start": start_time,
            "end": end_time,
            "word": line
        })
    
    try:
        subtitles.save(srt_output, encoding='utf-8')
        with open(json_output, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ã‚·ãƒ³ãƒ—ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº†ï¼")
        print(f"   â€¢ SRT: {srt_output}")
        print(f"   â€¢ JSON: {json_output}")
        return srt_output, json_output
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# ===== STEP 7: æ—¢å­˜ã®é–¢æ•°ç¾¤ï¼ˆæ”¹è‰¯ç‰ˆï¼‰ =====
def create_sample_audio(filename="sample_audio.wav", duration=6):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    sample_rate = 22050
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    frequencies = [440, 523, 659, 783, 659, 523]  # A-C-E-G-E-C
    audio = np.zeros_like(t)
    segment_len = len(t) // 6
    
    for i, freq in enumerate(frequencies):
        start = i * segment_len
        end = (i + 1) * segment_len if i < 5 else len(t)
        audio[start:end] = 0.3 * np.sin(2 * np.pi * freq * t[start:end])
    
    fade_len = int(0.1 * sample_rate)
    audio[:fade_len] *= np.linspace(0, 1, fade_len)
    audio[-fade_len:] *= np.linspace(1, 0, fade_len)
    
    audio_int16 = (audio * 32767).astype(np.int16)
    wavfile.write(filename, sample_rate, audio_int16)
    return filename

def create_sample_lyrics(filename="sample_lyrics.txt"):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«æ­Œè©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    lyrics = """Hello beautiful world
Music flows through my soul
Dancing with the melody
Creating magic together
Harmony fills the air
Peace and love forever"""
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(lyrics)
    return filename

def preview_subtitles(srt_file: str, lines_to_show: int = 5):
    """å­—å¹•ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"""
    print(f"\nğŸ“– å­—å¹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (æœ€åˆã®{lines_to_show}è¡Œ):")
    print("="*50)
    
    try:
        subtitles = pysrt.open(srt_file)
        for i, subtitle in enumerate(subtitles[:lines_to_show]):
            print(f"{subtitle.index}")
            print(f"{subtitle.start} --> {subtitle.end}")
            print(f"{subtitle.text}")
            print()
        
        if len(subtitles) > lines_to_show:
            print(f"... ä»– {len(subtitles) - lines_to_show} ã‚¨ãƒ³ãƒˆãƒª")
    except Exception as e:
        print(f"âŒ SRTãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def download_file(file_path: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    if os.path.exists(file_path):
        print(f"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {os.path.basename(file_path)}")
        try:
            files.download(file_path)
        except Exception as e:
            print(f"âš ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

def add_subtitles_to_video(video_clip, srt_file: str):
    """å‹•ç”»ã«å­—å¹•ã‚’ç„¼ãè¾¼ã¿"""
    try:
        subtitles = pysrt.open(srt_file)
        subtitle_clips = []
        
        for subtitle in subtitles:
            start_time = subtitle.start.ordinal / 1000.0
            end_time = subtitle.end.ordinal / 1000.0
            duration = end_time - start_time
            
            if duration > 0:
                try:
                    txt_clip = mp.TextClip(
                        subtitle.text,
                        fontsize=48,
                        color='white',
                        font='Arial-Bold',
                        stroke_color='black',
                        stroke_width=2,
                        size=(1800, None)
                    ).set_position(('center', 'bottom')).set_start(start_time).set_duration(duration)
                    subtitle_clips.append(txt_clip)
                except:
                    txt_clip = mp.TextClip(
                        subtitle.text,
                        fontsize=40,
                        color='white'
                    ).set_position(('center', 'bottom')).set_start(start_time).set_duration(duration)
                    subtitle_clips.append(txt_clip)
        
        if subtitle_clips:
            print(f"ğŸ“ {len(subtitle_clips)} å€‹ã®å­—å¹•ã‚¯ãƒªãƒƒãƒ—ã‚’è¿½åŠ ä¸­...")
            return mp.CompositeVideoClip([video_clip] + subtitle_clips)
        else:
            return video_clip
    except Exception as e:
        print(f"âš ï¸ å­—å¹•è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        return video_clip

def generate_video(wav_file: str, srt_file: str, output_dir: str = "./outputs"):
    """æœ€çµ‚çš„ãªéŸ³æ¥½ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    print("\nğŸ¬ å‹•ç”»ç”Ÿæˆé–‹å§‹...")
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        audio = mp.AudioFileClip(wav_file)
        audio_duration = audio.duration
        print(f"ğŸµ éŸ³å£°ã®é•·ã•: {audio_duration:.2f}ç§’")
    except Exception as e:
        print(f"âŒ éŸ³å£°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    print("ğŸ¨ ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³èƒŒæ™¯ã‚’ä½œæˆä¸­...")
    
    def make_gradient_frame(t):
        color_value = int(128 + 127 * np.sin(2 * np.pi * t / 4))
        return np.full((1080, 1920, 3), [color_value, 100, 255-color_value], dtype=np.uint8)
    
    video_clip = mp.VideoClip(make_gradient_frame, duration=audio_duration).resize((1920, 1080))
    
    print("ğŸ“ å­—å¹•è¿½åŠ ä¸­...")
    try:
        video_with_subs = add_subtitles_to_video(video_clip, srt_file)
    except Exception as e:
        print(f"âš ï¸ å­—å¹•è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        video_with_subs = video_clip
    
    final_video = video_with_subs.set_audio(audio)
    output_file = os.path.join(output_dir, f"{Path(wav_file).stem}_final_video.mp4")
    print(f"ğŸ’¾ å‹•ç”»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­: {output_file}")
    
    try:
        final_video.write_videofile(
            output_file, 
            fps=24, 
            codec='libx264', 
            audio_codec='aac', 
            temp_audiofile='temp-audio.m4a', 
            remove_temp=True, 
            verbose=False, 
            logger=None
        )
        print(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {output_file}")
        
        video_clip.close()
        if video_with_subs != video_clip:
            video_with_subs.close()
        final_video.close()
        audio.close()
        return output_file
    except Exception as e:
        print(f"âŒ å‹•ç”»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

print("âœ… é–¢æ•°å®šç¾©å®Œäº†ï¼")

# ===== STEP 8: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ =====
print("\nğŸš€ STEP 8: ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–‹å§‹")
print("="*50)

# APIè¨­å®š
print("\nğŸ”‘ APIè¨­å®šã‚’è¡Œã„ã¾ã™ã‹ï¼Ÿ")
print("   y: OpenAI/Runway APIã‚’è¨­å®šã—ã¦ãƒ•ãƒ«æ©Ÿèƒ½ã‚’ä½¿ç”¨")
print("   n: APIãªã—ã§åŸºæœ¬æ©Ÿèƒ½ã®ã¿ä½¿ç”¨")

use_api = input("é¸æŠã—ã¦ãã ã•ã„ (y/n): ").lower().strip()

openai_key = None
runway_key = None

if use_api == 'y' or use_api == 'yes':
    openai_key, runway_key = setup_apis()

# GPT-4oçµ±åˆãƒ‡ãƒ¢
if openai_key:
    print("\nğŸ¤– GPT-4oè‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ‡ãƒ¢")
    print("="*50)
    
    demo_prompts = generate_music_prompts_with_gpt4o(
        language="æ—¥æœ¬èª",
        description="æœªæ¥çš„ãªã‚·ãƒ³ã‚»ã‚¦ã‚§ãƒ¼ãƒ–ã€å®‡å®™ã‚’æ—…ã™ã‚‹æ­Œ",
        duration=120
    )
    
    print("ğŸµ ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    print(f"ã‚¿ã‚¤ãƒˆãƒ«: {demo_prompts['title']}")
    print(f"ã‚¹ã‚¿ã‚¤ãƒ«: {demo_prompts['style_prompt']}")
    print(f"æ­Œè©ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {demo_prompts['lyrics'][:100]}...")
    
    # æ­Œè©ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    with open("gpt4o_generated_lyrics.txt", "w", encoding="utf-8") as f:
        f.write(demo_prompts['lyrics'])
    print("ğŸ“ æ­Œè©ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: gpt4o_generated_lyrics.txt")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
print("\nğŸ§ª ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
sample_audio = create_sample_audio()
sample_lyrics = create_sample_lyrics()
print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†!")

# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
print("\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ")
print("="*50)
print("ğŸ§ª ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ")
print("   y: ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ãƒ»é«˜é€Ÿãƒ†ã‚¹ãƒˆï¼‰")
print("   n: ç‹¬è‡ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

use_sample = input("é¸æŠã—ã¦ãã ã•ã„ (y/n): ").lower().strip()

if use_sample == 'y' or use_sample == 'yes' or use_sample == '':
    audio_file = sample_audio
    lyrics_file = sample_lyrics
    print(f"\nâœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
else:
    print("\nğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:")
    print("ğŸµ WAVéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:")
    audio_files = files.upload()
    print("\nğŸ“ TXTæ­Œè©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:")
    lyrics_files = files.upload()
    
    audio_file = list(audio_files.keys())[0] if audio_files else None
    lyrics_file = list(lyrics_files.keys())[0] if lyrics_files else None

# ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆé¸æŠ
print("\nğŸ¯ ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ–¹æ³•é¸æŠ")
print("="*50)
print("ğŸ™ï¸ Whisperé«˜åº¦ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ")
print("   y: Whisperä½¿ç”¨ï¼ˆé«˜ç²¾åº¦ãƒ»æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰")
print("   n: ã‚·ãƒ³ãƒ—ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆé«˜é€Ÿãƒ»åŸºæœ¬ç²¾åº¦ï¼‰")

use_whisper = input("é¸æŠã—ã¦ãã ã•ã„ (y/n): ").lower().strip()

# å®Ÿè¡Œ
if audio_file and lyrics_file:
    # ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå®Ÿè¡Œ
    if use_whisper == 'y' or use_whisper == 'yes':
        srt_file, json_file = advanced_align_with_whisper(audio_file, lyrics_file)
    else:
        srt_file, json_file = simple_align_subtitles(audio_file, lyrics_file)
    
    if srt_file:
        # å­—å¹•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        preview_subtitles(srt_file, lines_to_show=3)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print("\nğŸ“¥ å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
        download_file(srt_file)
        if json_file:
            download_file(json_file)
        
        # å‹•ç”»ç”Ÿæˆ
        final_video_path = generate_video(audio_file, srt_file)
        
        if final_video_path:
            # å‹•ç”»æƒ…å ±è¡¨ç¤º
            try:
                video_size = os.path.getsize(final_video_path) / (1024 * 1024)
                print(f"\nğŸ“Š æœ€çµ‚å‹•ç”»æƒ…å ±:")
                print(f"   ãƒ•ã‚¡ã‚¤ãƒ«å: {os.path.basename(final_video_path)}")
                print(f"   ã‚µã‚¤ã‚º: {video_size:.1f} MB")
            except:
                pass
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print("\nğŸ“¥ å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
            download_file(final_video_path)
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            try:
                print("\nğŸ¥ å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
                display(Video(final_video_path, width=640, height=360))
            except:
                pass
            
            print("\nğŸ‰ AIéŸ³æ¥½ãƒ“ãƒ‡ã‚ªç”Ÿæˆå®Œäº†ï¼")
        else:
            print("\nâŒ å‹•ç”»ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        print("\nâŒ ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
else:
    print("\nâŒ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

print("\n" + "="*70)
print("ğŸ”— GitHub: https://github.com/yusuke10151985/amvc")
print("ğŸš€ AIéŸ³æ¥½ãƒ“ãƒ‡ã‚ªã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ - APIçµ±åˆç‰ˆ çµ‚äº†")
print("\nâœ¨ æ–°æ©Ÿèƒ½:")
print("   â€¢ GPT-4oè‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ")
print("   â€¢ Whisperé«˜åº¦ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ")
print("   â€¢ APIçµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")
print("   â€¢ Runway Gen-4å¯¾å¿œæº–å‚™å®Œäº†") 